例: huyaAll项目
管道的持久化存储
    - 数据解析(爬虫类)
    - 将解析的数据封装到item类型的对象中(爬虫类)
    - 将item提交给管道: yield itme(爬虫类)
    - 在管道类的process_item中接收item对象并且进行任意形式的持久化存储操作(管道类)
    - 细节:
        - 将爬取的数据进行备份?
            - 一个管道类对应一种平台的持久化存储
        - 有多个管道类是否意味眷多个管道类都可以接受到爬虫文件提交的item?
            - 只有优先级最高的管道类才可以接受到item,剩下的管道类是需要从优先级最高的管道类中接收item
- 基于Spider父类进行全栈数据的爬取
    - 全站数据的爬取:将所有的页码对应的页面数据进行爬取
    - 手动请求的发送(get):
        scrapy.Request(url, callback)
    - 对yield的总结:
        - 向管道提交item的时候:yield item
        - 手动请求发送: yield scrapy.Request(url, callback)
    - 手动发起post请求(用的request模块比较多):
        yield scrapy.FormRequest(url, formdata, callback): fromdata是一个字典表示请求参数

- scrapy五大核心组件
    1.引擎(Scrapy)
        用来处理整个系统的数据流处理,触发事务(框架核心)
    2.爬虫(Spiders)
        爬虫主要干活的,用于从特定的网页中提取自己需要的信息,即所谓的实体(Item).用户也可以从中提取出链接,让Scrapy继续抓取下一个页面
    3.调度器(Scheduler)
        用来接受引擎发过来的请求,压入队列中,并在引擎再次请求的时候返回,可以想像成一个URL(抓取网页的网址或者说是
        链接)的优先队列,由它来决定下一个要抓取的网址是什么,同时去除重复的网址
    4.项目管道(Pipeline)
        负责处理爬虫从网页中抽取的实体,主要的功能是持久化实体、验证实体的有效性、清除不需要的信息。当页面被爬虫解析后，将被发送到项目管道，并
        经过几个特定的次序处理数据。
    5.下载器(Downloader)
        用于下载网页内容,并将网页内容返回给蜘蛛(Scrapy下载器是建立在twisted这个高效的异步模型上的)

- scrapy请求传参
- scrapy的中间件